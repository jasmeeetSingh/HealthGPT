{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a266523-111c-481b-852c-626c00610fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "df = pd.read_csv('data.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16b5ea7-6cee-4f04-a3be-27214737f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['transcription', 'keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4c2117-60f1-4318-9089-e6a2533964b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62cab107-b677-4968-9aae-316125f14044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install tensorboard\n",
    "# !pip install tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0b8ab1-a164-4ec2-b92e-f87da1d4e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e15573b-9252-4903-bb7e-f3bb528077ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "314cc71f-9e16-4970-9d1e-d9453b8ed9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfc2b380-2f6d-4273-a764-3dccb2d31b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset for training\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, input_texts, target_queries, tokenizer, task_prefix):\n",
    "        self.input_texts = input_texts\n",
    "        self.target_queries = target_queries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.task_prefix = task_prefix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        input_text = self.task_prefix + self.input_texts[index]\n",
    "        target_query = self.target_queries[index]\n",
    "\n",
    "        input_encoding = self.tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        target_encoding = self.tokenizer(target_query, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.squeeze(0),\n",
    "            'attention_mask': input_encoding.attention_mask.squeeze(0),\n",
    "            'labels': target_encoding.input_ids.squeeze(0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f771b1-b09c-4ea8-9333-511f6d938123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled dataset\n",
    "df1 = df.sample(500)\n",
    "input_texts = df1.transcription.values # List of input texts\n",
    "target_queries = df1.keywords.values  # List of corresponding target SQL queries\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_input_texts, val_input_texts, train_target_queries, val_target_queries = train_test_split(input_texts, target_queries, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8fc2edc-c962-4acf-9883-1185d6acd422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the custom dataset\n",
    "task_prefix = 'Create a summary for '\n",
    "train_dataset = Dataset(train_input_texts, train_target_queries, tokenizer, task_prefix)\n",
    "val_dataset = Dataset(val_input_texts, val_target_queries, tokenizer, task_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61943211-96fe-4d70-9ddc-9e9fef4157f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training hyperparameters\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Define the optimier and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24d8ddc4-d757-443b-9d88-985ae7e86145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e7588d-490e-48b7-bd52-d33d1c68066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05fcb753-f478-40c0-92d5-2606d246a2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66814909b6304f3d95d6bcab5fd8ba94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8292591d543464d9b22dfdf97a5af4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25255f807ae14ffa8f08b8376be15ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss 0.2441992333624512 0\n",
      "Epoch: 1, Validation Loss: 0.2442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e519a26a91f48c7ab8360becc299461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633c567b06a0412d97c74dba63819115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss 0.2392995275557041 1\n",
      "Epoch: 2, Validation Loss: 0.2393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7ae743a65b4f459fa3a97f324bb1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa7479cf1994d3cb021f0fd6e19dbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss 0.2375073814485222 2\n",
      "Epoch: 3, Validation Loss: 0.2375\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), labels=labels.to(device))\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), labels=labels.to(device))\n",
    "            val_loss = outputs.loss\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f'Epoch: {epoch+1}, Validation Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caf2a5ea-cdff-405a-a360-ec6afdd6b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a summary for 1.  The left ventricular cavity size and wall thickness appear normal.  The wall motion and left ventricular systolic function appears hyperdynamic with estimated ejection fraction of 70% to 75%.  There is near-cavity obliteration seen.  There also appears to be increased left ventricular outflow tract gradient at the mid cavity level consistent with hyperdynamic left ventricular systolic function.  There is abnormal left ventricular relaxation pattern seen as well as elevated left atrial pressures seen by Doppler examination.,2.  The left atrium appears mildly dilated.,3.  The right atrium and right ventricle appear normal.,4.  The aortic root appears normal.,5.  The aortic valve appears calcified with mild aortic valve stenosis, calculated aortic valve area is 1.3 cm square with a maximum instantaneous gradient of 34 and a mean gradient of 19 mm.,6.  There is mitral annular calcification extending to leaflets and supportive structures with thickening of mitral valve leaflets with mild mitral regurgitation.,7.  The tricuspid valve appears normal with trace tricuspid regurgitation with moderate pulmonary artery hypertension.  Estimated pulmonary artery systolic pressure is 49 mmHg.  Estimated right atrial pressure of 10 mmHg.,8.  The pulmonary valve appears normal with trace pulmonary insufficiency.,9.  There is no pericardial effusion or intracardiac mass seen.,10.  There is a color Doppler suggestive of a patent foramen ovale with lipomatous hypertrophy of the interatrial septum.,11.  The study was somewhat technically limited and hence subtle abnormalities could be missed from the study.,\n",
      "cardiovascular / pulmonary, 2-d, doppler, echocardiogram, annular, aortic root, aortic valve, atrial, atrium, calcification, cavity, ejection fraction, mitral, obliteration, outflow, regurgitation, relaxation pattern, stenosis, systolic function, tricuspid, valve, ventricular, ventricular cavity, wall motion, pulmonary artery\n",
      "<pad>cardiovascular / pulmonary, ventricular artery, ventricular artery, ventricular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_text = task_prefix + df.transcription.iloc[4]\n",
    "input_encoding = tokenizer([input_text], return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "input_ids = input_encoding['input_ids']\n",
    "attention_mask = input_encoding['attention_mask']\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device))\n",
    "    print(input_text)\n",
    "    print(df.keywords.iloc[4])\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d432396-cc22-4a7f-ab5b-c953fd68e912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
